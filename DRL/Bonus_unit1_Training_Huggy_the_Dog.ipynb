{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amir-Kermanshahani/AI/blob/main/DRL/Bonus_unit1_Training_Huggy_the_Dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WNoL04M7rTa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Cloning the repository\n",
        "!git clone --depth 1 https://github.com/Unity-Technologies/ml-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8wmVcMk7xKo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Istall the packages from the repository\n",
        "%cd ml-agents\n",
        "!pip3 install -e ./ml-agents-envs\n",
        "!pip3 install -e ./ml-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9Ls6_6eOKiA"
      },
      "outputs": [],
      "source": [
        "# Placing the environment executable in a zip file inside our directory\n",
        "!mkdir ./trained-envs-executables\n",
        "!mkdir ./trained-envs-executables/linux"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the Huggy.zip\n",
        "!wget \"https://github.com/huggingface/Huggy/raw/main/Huggy.zip\" -O ./trained-envs-executables/linux/Huggy.zip"
      ],
      "metadata": {
        "id": "8xNAD1tRpy0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FPx0an9IAwO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Unzipping the downloaded zip file\n",
        "!unzip -d ./trained-envs-executables/linux/ ./trained-envs-executables/linux/Huggy.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdFsLJ11JvQf"
      },
      "outputs": [],
      "source": [
        "# Making sure the file is accessible\n",
        "!chmod -R 755 ./trained-envs-executables/linux/Huggy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "State Space:\n",
        "- The target (stick) position\n",
        "- The relative position between himself and the target\n",
        "- The orientation of his legs.\n",
        "\n",
        "Action Space:\n",
        "Rotating joint motors\n",
        "\n",
        "Reward Function:\n",
        "- Orientation bonus: we reward him for getting close to the target.\n",
        "- Time penalty: a fixed-time penalty given at every action to force him to get to the stick as fast as possible.\n",
        "- Rotation penalty: we penalize Huggy if he spins too much and turns too quickly.\n",
        "- Getting to the target reward: we reward Huggy for reaching the target.\n",
        "\n",
        "Find configuration parameters at: https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SliITGWxOVwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS-Yh1UdHfzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a54f06cb-b887-4e72-fde2-e7cabc5de8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-10 15:50:25.125982: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-10 15:50:25.147295: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-10 15:50:25.153357: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-10 15:50:25.168044: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-10 15:50:26.359983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 1.2.0.dev0,\n",
            "  ml-agents-envs: 1.2.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 2.5.1+cu121\n",
            "[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n",
            "[INFO] Connected new brain: Huggy?team=0\n",
            "[INFO] Hyperparameters for behavior name Huggy: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t2048\n",
            "\t  buffer_size:\t20480\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  shared_critic:\tFalse\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tcheckpoint_interval:\t200000\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tTrue\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t3\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.995\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t15\n",
            "\teven_checkpoints:\tFalse\n",
            "\tmax_steps:\t2000000\n",
            "\ttime_horizon:\t1000\n",
            "\tsummary_freq:\t50000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "[INFO] Huggy. Step: 50000. Time Elapsed: 70.299 s. Mean Reward: 1.739. Std of Reward: 0.944. Training.\n",
            "[INFO] Huggy. Step: 100000. Time Elapsed: 129.598 s. Mean Reward: 2.543. Std of Reward: 1.063. Training.\n",
            "[INFO] Huggy. Step: 150000. Time Elapsed: 190.045 s. Mean Reward: 3.103. Std of Reward: 1.148. Training.\n",
            "[INFO] Huggy. Step: 200000. Time Elapsed: 249.821 s. Mean Reward: 3.282. Std of Reward: 1.275. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-199871.onnx\n",
            "[INFO] Huggy. Step: 250000. Time Elapsed: 311.187 s. Mean Reward: 3.492. Std of Reward: 1.467. Training.\n",
            "[INFO] Huggy. Step: 300000. Time Elapsed: 370.913 s. Mean Reward: 3.674. Std of Reward: 1.544. Training.\n",
            "[INFO] Huggy. Step: 350000. Time Elapsed: 430.556 s. Mean Reward: 3.714. Std of Reward: 1.605. Training.\n",
            "[INFO] Huggy. Step: 400000. Time Elapsed: 494.580 s. Mean Reward: 3.663. Std of Reward: 1.528. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-399892.onnx\n",
            "[INFO] Huggy. Step: 450000. Time Elapsed: 556.184 s. Mean Reward: 3.787. Std of Reward: 1.650. Training.\n",
            "[INFO] Huggy. Step: 500000. Time Elapsed: 619.602 s. Mean Reward: 3.858. Std of Reward: 1.780. Training.\n",
            "[INFO] Huggy. Step: 550000. Time Elapsed: 680.936 s. Mean Reward: 3.760. Std of Reward: 1.717. Training.\n",
            "[INFO] Huggy. Step: 600000. Time Elapsed: 745.145 s. Mean Reward: 3.932. Std of Reward: 1.807. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-599978.onnx\n",
            "[INFO] Huggy. Step: 650000. Time Elapsed: 821.724 s. Mean Reward: 3.814. Std of Reward: 1.700. Training.\n",
            "[INFO] Huggy. Step: 700000. Time Elapsed: 898.310 s. Mean Reward: 3.840. Std of Reward: 1.673. Training.\n",
            "[INFO] Huggy. Step: 750000. Time Elapsed: 961.547 s. Mean Reward: 3.842. Std of Reward: 1.728. Training.\n",
            "[INFO] Huggy. Step: 800000. Time Elapsed: 1024.407 s. Mean Reward: 3.805. Std of Reward: 1.617. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-799958.onnx\n",
            "[INFO] Huggy. Step: 850000. Time Elapsed: 1090.203 s. Mean Reward: 3.936. Std of Reward: 1.712. Training.\n",
            "[INFO] Huggy. Step: 900000. Time Elapsed: 1151.167 s. Mean Reward: 3.787. Std of Reward: 1.710. Training.\n",
            "[INFO] Huggy. Step: 950000. Time Elapsed: 1216.161 s. Mean Reward: 3.894. Std of Reward: 1.775. Training.\n",
            "[INFO] Huggy. Step: 1000000. Time Elapsed: 1279.618 s. Mean Reward: 3.806. Std of Reward: 1.719. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-999939.onnx\n",
            "[INFO] Huggy. Step: 1050000. Time Elapsed: 1341.620 s. Mean Reward: 3.899. Std of Reward: 1.690. Training.\n",
            "[INFO] Huggy. Step: 1100000. Time Elapsed: 1407.311 s. Mean Reward: 3.822. Std of Reward: 1.698. Training.\n",
            "[INFO] Huggy. Step: 1150000. Time Elapsed: 1469.442 s. Mean Reward: 3.842. Std of Reward: 1.724. Training.\n",
            "[INFO] Huggy. Step: 1200000. Time Elapsed: 1533.397 s. Mean Reward: 3.933. Std of Reward: 1.769. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-1199937.onnx\n",
            "[INFO] Huggy. Step: 1250000. Time Elapsed: 1596.118 s. Mean Reward: 3.732. Std of Reward: 1.675. Training.\n",
            "[INFO] Huggy. Step: 1300000. Time Elapsed: 1662.189 s. Mean Reward: 3.975. Std of Reward: 1.797. Training.\n",
            "[INFO] Huggy. Step: 1350000. Time Elapsed: 1723.425 s. Mean Reward: 3.985. Std of Reward: 1.744. Training.\n",
            "[INFO] Huggy. Step: 1400000. Time Elapsed: 1784.386 s. Mean Reward: 3.845. Std of Reward: 1.733. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-1399904.onnx\n",
            "[INFO] Huggy. Step: 1450000. Time Elapsed: 1849.429 s. Mean Reward: 3.842. Std of Reward: 1.761. Training.\n",
            "[INFO] Huggy. Step: 1500000. Time Elapsed: 1913.398 s. Mean Reward: 3.910. Std of Reward: 1.720. Training.\n",
            "[INFO] Huggy. Step: 1550000. Time Elapsed: 1979.816 s. Mean Reward: 3.805. Std of Reward: 1.797. Training.\n",
            "[INFO] Huggy. Step: 1600000. Time Elapsed: 2040.742 s. Mean Reward: 3.800. Std of Reward: 1.815. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-1599964.onnx\n",
            "[INFO] Huggy. Step: 1650000. Time Elapsed: 2105.400 s. Mean Reward: 3.856. Std of Reward: 1.827. Training.\n",
            "[INFO] Huggy. Step: 1700000. Time Elapsed: 2168.123 s. Mean Reward: 3.911. Std of Reward: 1.830. Training.\n",
            "[INFO] Huggy. Step: 1750000. Time Elapsed: 2231.849 s. Mean Reward: 3.778. Std of Reward: 1.818. Training.\n",
            "[INFO] Huggy. Step: 1800000. Time Elapsed: 2297.920 s. Mean Reward: 3.809. Std of Reward: 1.835. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-1799962.onnx\n",
            "[INFO] Huggy. Step: 1850000. Time Elapsed: 2359.643 s. Mean Reward: 3.859. Std of Reward: 1.754. Training.\n",
            "[INFO] Huggy. Step: 1900000. Time Elapsed: 2425.827 s. Mean Reward: 3.849. Std of Reward: 1.758. Training.\n",
            "[INFO] Huggy. Step: 1950000. Time Elapsed: 2486.668 s. Mean Reward: 3.841. Std of Reward: 1.790. Training.\n",
            "[INFO] Huggy. Step: 2000000. Time Elapsed: 2552.375 s. Mean Reward: 3.835. Std of Reward: 1.826. Training.\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-1999944.onnx\n",
            "[INFO] Exported results/Huggy2/Huggy/Huggy-2000019.onnx\n",
            "[INFO] Copied results/Huggy2/Huggy/Huggy-2000019.onnx to results/Huggy2/Huggy.onnx.\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "\n",
        "\"\"\"\n",
        "  mlagents-learn <config>: the path where the hyperparameter config file is.\n",
        "--env: where the environment executable is.\n",
        "--run-id: the name you want to give to your training run id.\n",
        "--no-graphics: to not launch the visualization during the training.\n",
        "\n",
        "Train the model and use the --resume flag to continue training in case of interruption.\n",
        "\"\"\"\n",
        "!mlagents-learn ./config/ppo/Huggy.yaml --env=./trained-envs-executables/linux/Huggy/Huggy --run-id=\"Huggy2\" --no-graphics"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}